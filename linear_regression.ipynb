{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split,  KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set()\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, be sure to download the dataset\n",
    "filename: str = 'dataset.csv'\n",
    "dataset = pd.read_pickle('dataRead_processed.pkl.bz2', compression='bz2')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "fig, axes = plt.subplots(6,7,figsize=(26,20))\n",
    "\n",
    "# We will not plot country because it has too many categories.\n",
    "for i, c in enumerate(dataset.columns[1:]):\n",
    "    ax = axes.reshape(-1)[i]\n",
    "    if dataset[c].dtype.kind == 'O':\n",
    "        a = sns.countplot(x=c,data=dataset,ax=ax)\n",
    "    else:\n",
    "        b = sns.histplot(x=c,data=dataset,ax=ax)\n",
    "    t = ax.set_title(c)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['total_passengers_2015',\n",
    "                      'total_passengers_and_non_passengers_2022',\n",
    "                      'total_passengers_and_non_passengers_2015',\n",
    "                      'total_passengers_and_non_passengers_2022_std',\n",
    "                      'total_passengers_2022_bx',\n",
    "                      'total_passengers_and_non_passengers_2022_bx',\n",
    "                      'total_passengers_2022_BC',\n",
    "                      'total_passengers_2022_min_max',\n",
    "                      'total_passengers_and_non_passengers_2022_min_max',\n",
    "                      'total_passengers_2022_std',\n",
    "                      ], inplace=True)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "\n",
    "X = dataset.loc[:,dataset.columns != 'total_passengers_2022']\n",
    "y = dataset['total_passengers_2022']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, # Features\n",
    "                                                    y, # Target\n",
    "                                                    test_size=0.33, # Percentage of the dataset to be used as test set\n",
    "                                                    random_state=10 # Seed\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_preprocessing(X, y):\n",
    "    print('Original shape:{}'.format(X.shape))\n",
    "    categorical_columns = X.dtypes[X.dtypes == 'category'].index.values\n",
    "    object_columns = X.dtypes[X.dtypes == 'object'].index.values\n",
    "    # We kill categorical columns\n",
    "    X=X.drop(columns=categorical_columns)\n",
    "    X=X.drop(columns=object_columns)\n",
    "    print('Droped category: {}'.format(categorical_columns))\n",
    "    print('Droped object: {}'.format(object_columns))\n",
    "    # We remove missing values\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    print('New shape:{}'.format(X.shape))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = minimum_preprocessing(X_train,y_train)\n",
    "X_test, y_test = minimum_preprocessing(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We instantiate a linear regression. \n",
    "lr = LinearRegression() # From sklearn\n",
    "\n",
    "# Fit the model using the training set\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# Predict the target using the training set\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "weights = lr.coef_\n",
    "intercept = lr.intercept_\n",
    "# You can access to some info about the model, like the weights.\n",
    "print('Coefficients: \\n', weights[:10])\n",
    "print('Intercept: \\n', intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use sklearn implementation\n",
    "mean_square_error_sk = mean_squared_error(y_train, y_pred)\n",
    "mean_square_error_sk\n",
    "\n",
    "# MSE is the average of the square of the errors. The larger the number, the larger the error.\n",
    "norm_mse_sk = 1-r2_score(y_train, y_pred)\n",
    "\n",
    "R_squared_sk = r2_score(y_train,y_pred) \n",
    "\n",
    "mean_square_error_sk, norm_mse_sk, R_squared_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_metrics = pd.DataFrame(columns=['MSE', 'norm_MSE', 'R2'])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "i=1\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Split {}: \\n\\tTest Folds: [{}] \\n\\tTrain Folds {}'.format(i, i, [j for j in range(1,6) if j != i]))\n",
    "    \n",
    "    x_train_fold = X_train.values[train_index]\n",
    "    y_train_fold = y_train.values[train_index]\n",
    "    x_test_fold = X_train.values[test_index,:]\n",
    "    y_test_fold = y_train.values[test_index]\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train_fold,y_train_fold)\n",
    "    y_pred_fold = lr.predict(x_test_fold)\n",
    "    fold_mse =mean_squared_error(y_test_fold, y_pred_fold)\n",
    "    fold_nmse =  1-r2_score(y_test_fold, y_pred_fold)\n",
    "    fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "    print('\\tMSE: {} NMSE: {} R2: {}'.format(fold_mse,fold_nmse, fold_r2) )\n",
    "\n",
    "    cross_val_metrics.loc['Fold {}'.format(i), :] = [fold_mse,fold_nmse, fold_r2]\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "cross_val_metrics.loc['Mean',:] = cross_val_metrics.mean()\n",
    "cross_val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "folds_r2 = cross_val_score(lr, X_train,y_train, cv=5, scoring='r2')\n",
    "lr_r2 = np.mean(folds_r2) \n",
    "folds_r2, lr_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_metrics = pd.DataFrame(columns=['MSE', 'norm_MSE', 'R2'])\n",
    "\n",
    "def get_best_ridge_regression_parameter(hyperparameters: list[float],\n",
    "                                        X_train: pd.DataFrame,\n",
    "                                        y_train: pd.Series,\n",
    "                                        cv=5\n",
    "                                        ) -> float:\n",
    "    \"\"\"\n",
    "    Cross validation for Ridge regression.\n",
    "    Parameters:\n",
    "    hyperparameters: list of lambda values to be tested\n",
    "    X_train: Training set\n",
    "    y_train: Target\n",
    "    cv: Number of folds\n",
    "    \n",
    "    return best model hyperparameter\n",
    "    \"\"\"\n",
    "    ridge_cross_val_metrics = pd.DataFrame(columns=['mean MSE', 'mean norm_MSE', 'mean R2'])\n",
    "\n",
    "\n",
    "    for lambda_val in hyperparameters:\n",
    "        kf = KFold(n_splits=cv)\n",
    "        i=1\n",
    "        cv_mse = []\n",
    "        cv_nmse = []\n",
    "        cv_r2 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            print('Hyperparameter: {}\\n\\tSplit {}: \\n\\t\\tTest Folds: [{}] \\n\\t\\tTrain Folds {}'.format(lambda_val, i, i, [j for j in range(1,6) if j != i]))\n",
    "            \n",
    "            x_train_fold = X_train.values[train_index]\n",
    "            y_train_fold = y_train.values[train_index]\n",
    "            x_test_fold = X_train.values[test_index,:]\n",
    "            y_test_fold = y_train.values[test_index]\n",
    "\n",
    "            lr = Ridge(alpha=lambda_val)\n",
    "            lr.fit(x_train_fold,y_train_fold)\n",
    "            y_pred_fold = lr.predict(x_test_fold)\n",
    "            \n",
    "            fold_mse = mean_squared_error(y_test_fold, y_pred_fold)\n",
    "            fold_nmse = 1-r2_score(y_test_fold, y_pred_fold)\n",
    "            fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "            cv_mse.append(fold_mse)\n",
    "            cv_nmse.append(fold_nmse)\n",
    "            cv_r2.append(fold_r2)\n",
    "            print('\\t\\tMSE: {} NMSE: {} R2: {}'.format(fold_mse,fold_nmse, fold_r2) )\n",
    "        \n",
    "        ridge_cross_val_metrics.loc['Lambda={}'.format(lambda_val),:] = [np.mean(cv_mse),np.mean(cv_nmse),np.mean(cv_r2)]\n",
    "\n",
    "    ridge_cross_val_metrics.sort_values(by='mean R2',ascending=False)\n",
    "    \n",
    "    # Return the best model\n",
    "    best_lambda = ridge_cross_val_metrics.idxmax(axis=0)['mean R2']\n",
    "    \n",
    "    # Extract number from string\n",
    "    best_lambda = float(best_lambda.split('=')[1])\n",
    "    \n",
    "    return best_lambda\n",
    "\n",
    "def cross_validation_ridge_regression(best_hyperparameter: float,\n",
    "                                      X_train: pd.DataFrame,\n",
    "                                      y_train: pd.Series,\n",
    "                                      cv=5\n",
    "                                      ) -> Ridge:\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    i=1\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_train):        \n",
    "        x_train_fold = X_train.values[train_index]\n",
    "        y_train_fold = y_train.values[train_index]\n",
    "        x_test_fold = X_train.values[test_index,:]\n",
    "        y_test_fold = y_train.values[test_index]\n",
    "        \n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x_train_fold,y_train_fold)\n",
    "        y_pred_fold = lr.predict(x_test_fold)\n",
    "        fold_mse =mean_squared_error(y_test_fold, y_pred_fold)\n",
    "        fold_nmse =  1-r2_score(y_test_fold, y_pred_fold)\n",
    "        fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "\n",
    "        cross_val_metrics.loc['Fold {}'.format(i), :] = [fold_mse,fold_nmse, fold_r2]\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "    cross_val_metrics.loc['Mean',:] = cross_val_metrics.mean()\n",
    "    cross_val_metrics\n",
    "    return \n",
    "    \n",
    "# lambdas = [1e-10,1e-5,1e-4,1e-3,1e-2,0.1, 0.5,1,5,10,50,100]\n",
    "lambdas = np.logspace(start = -4, stop = 1.1, num = 100, base = 10.0)\n",
    "\n",
    "\n",
    "get_best_ridge_regression_parameter(hyperparameters=lambdas, X_train=X_train, y_train=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with the best hyperparameter\n",
    "best_lambda = get_best_ridge_regression_parameter(hyperparameters=lambdas, X_train=X_train, y_train=y_train)\n",
    "\n",
    "print(f\"Best lambda: {best_lambda}\")\n",
    "\n",
    "# Use cross validation\n",
    "ridge = Ridge(alpha=best_lambda)\n",
    "ridge.fit(X_train,y_train, )\n",
    "y_pred = ridge.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)   # computes means and stdevs for each column in X_train\n",
    "X_train_scaled = scaler.transform(X_train)             # substracts mean and divides by stdev (estimated from training)\n",
    "X_test_scaled = scaler.transform(X_test)               # substracts mean and divides by stdev (estimated from training)\n",
    "\n",
    "X_train_scaled[:,0] = 1   # undo transformation for all-1 column\n",
    "X_test_scaled[:,0] = 1   # undo transformation for all-1 column\n",
    "\n",
    "print(X_train_scaled.mean(axis=0))\n",
    "print(X_test_scaled.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lambdas = np.logspace(start = -4, stop = 1.1, num = 100, base = 10.0)\n",
    "results = []\n",
    "\n",
    "X = X_train_scaled.copy()\n",
    "y = y_train.copy()\n",
    "n = y.shape[0]\n",
    "d = X.shape[1]\n",
    "\n",
    "\n",
    "for l in lambdas:\n",
    "    XtX = X.T @ X\n",
    "    XtX_inv = np.linalg.inv( XtX + l * np.identity(n=d))\n",
    "    coefs = (XtX_inv) @ X.T @ y\n",
    "    hatmat = X @ XtX_inv @ X.T\n",
    "    trace_hatmat = np.trace(hatmat)\n",
    "    y_pred = X @ coefs\n",
    "    \n",
    "    loocv = 1/n * np.sum([((y.iloc[i] - y_pred[i]) / (1 - hatmat[i,i]))**2 for i in range(n)])\n",
    "    \n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    gcv = mse / (1 - trace_hatmat/n)**2\n",
    "    results.append([l, mse, loocv, gcv])\n",
    "\n",
    "df = pd.DataFrame(results, columns = ['lambda', 'training_mse', 'loocv', 'gcv']) \n",
    "df.sort_values(by='loocv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='line', x='lambda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = df.loc[df['loocv'].idxmin()]['lambda']\n",
    "\n",
    "print(f'best lambda value: {best_lambda:.4f}')\n",
    "\n",
    "# apply formula with \"best lambda\"\n",
    "theta_vector = np.linalg.inv( X_train_scaled.T @ X_train_scaled + best_lambda * np.identity(n=d)) @ X_train_scaled.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "print(f'there are {X_train_scaled.shape[0]} training examples.')\n",
    "results = []\n",
    "for k in range(2, 6+1):\n",
    "    ridge = RidgeCV(alphas=lambdas, fit_intercept=False, cv=k)   #k-fold cross-val\n",
    "    clf = ridge.fit(X_train_scaled, y_train)\n",
    "    results.append([k, clf.alpha_])\n",
    "\n",
    "## \"efficient\"  way:\n",
    "ridge = RidgeCV(alphas=lambdas, fit_intercept=False, cv=None)\n",
    "clf = ridge.fit(X_train_scaled, y_train)\n",
    "results.append(['efficient', clf.alpha_])\n",
    "\n",
    "pd.DataFrame(results, columns=['cross-val method (k)', 'best lambda'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
