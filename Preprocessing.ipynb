{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra imports\n",
    "from pandas import read_csv\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "from distance_calculation import distance_to_paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1: READING THE FILE DATASET.CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead = read_csv(data, header=0, delimiter=';')\n",
    "dataRead.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Question:\n",
    "\n",
    "* Which is the target variable? where is it? how many different values? is it a classification problem or a regression problem?\n",
    "\n",
    "* The target variable is located in column 3 and is called 'total_passengers_2022'; it has two possible values (therfore it is a classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 2: BASIC INSPECTION OF THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations\n",
    "\n",
    "Zero Values: Columns such as total_passengers_2022 and total_passengers_and_non_passengers_2022 have zero values. These may need special handling.\n",
    "\n",
    "High Variability: Many columns, like total_passengers_2022, have high standard deviations, indicating significant variability in the data.\n",
    "\n",
    "Missing Data: Columns like distr_histoires_courtes and total have significantly fewer entries, suggesting missing data that may need imputation or dropping.\n",
    "\n",
    "Next Steps\n",
    "Handle Missing Values: Impute or remove missing values appropriately.\n",
    "Normalize Data: Normalize or standardize numerical columns to prepare for machine learning models.\n",
    "Outlier Treatment: Identify and handle outliers in the data to ensure robust analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove services except wifi, trigram, city code, uic, postal code, Total Voyageurs 2021, city_attraction_label, active_employers_2021, hotel_rooms_2024_sum, camping_sites_2024_sum.1\n",
    "# split geographical_position\n",
    "#Assign No for missing WIFI\n",
    "\n",
    "columns_to_drop = [\n",
    "    'trigram', 'city_code', 'uic', 'postal_code', 'Total Voyageurs 2021',\n",
    "    'city_attraction_label', 'active_employers_2021', 'hotel_rooms_2024_sum',\n",
    "    'camping_sites_2024_sum.1','power_station','baby_foot','piano', 'distr_histoires_courtes','total'\n",
    "]\n",
    "dataRead.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Splitting geographical_position into latitude and longitude\n",
    "dataRead[['latitude', 'longitude']] = dataRead['geographical_position'].str.split(',', expand=True)\n",
    "dataRead.drop(columns=['geographical_position'], axis=1, inplace=True)\n",
    "\n",
    "dataRead.describe()\n",
    "dataRead.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 3: DEALING WITH MISSING VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we decide to remove the missing values for some of the numerical variables as there are few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataRead.total_passengers_2022\t==0).value_counts()\n",
    "(dataRead.total_passengers_and_non_passengers_2022\t==0).value_counts()\n",
    "(dataRead.total_passengers_2015\t==0).value_counts()\n",
    "(dataRead.total_passengers_and_non_passengers_2015\t==0).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead=  dataRead[(dataRead.total_passengers_2022!=0) & (dataRead.total_passengers_and_non_passengers_2022!=0) \n",
    "                    & (dataRead.total_passengers_2015!=0) & (dataRead.total_passengers_and_non_passengers_2015!=0)]\n",
    "dataRead.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified that the `wifi_service` column contains the values 'Non' (No), 'Oui' (Yes), and some missing values (`NaN`). The distribution of these values was as follows:\n",
    "\n",
    "- **Non**: 2106\n",
    "- **Oui**: 120\n",
    "- **NaN**: 8\n",
    "\n",
    "### Strategy\n",
    "\n",
    "To handle the missing values and convert the categorical values to binary, we:\n",
    "1. Removed rows with `NaN` values in the `wifi_service` column.\n",
    "2. Converted 'Oui' to 1 and 'Non' to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN values in wifi_service\n",
    "dataRead = dataRead.dropna(subset=['wifi_service'])\n",
    "\n",
    "# Convert 'Oui' to 1 and 'Non' to 0 in wifi_service\n",
    "dataRead['wifi_service'] = dataRead['wifi_service'].map({'Oui': 1, 'Non': 0})\n",
    "\n",
    "# Display the updated frequency of each value in wifi_service column\n",
    "wifi_service_value_counts = dataRead['wifi_service'].value_counts(dropna=False)\n",
    "wifi_service_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 4: FINDING OUTLIERS\n",
    "\n",
    "In real data you are usually going to find outliers. It can be because the data is just like that or because there are wrong values stored.\n",
    "\n",
    "It is important to identify them so you can remove them, impute them, or just acknowledge their existence and take into account in your analysis.\n",
    "\n",
    "Some machine learning models are very sensitive to outliers.\n",
    "\n",
    "There are a lot of ways to define an outlier. Here we are going to talk about a basic and a complex one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'total_passengers_2022',\n",
    "    'total_passengers_and_non_passengers_2022',\n",
    "    'total_passengers_2015',\n",
    "    'total_passengers_and_non_passengers_2015',\n",
    "    'sum_municipal_population_2021',\n",
    "    'non_scholarized_15_years_old_or_more_2020',\n",
    "    'main_residences_2020',\n",
    "    'housing_2020',\n",
    "    'jobs_at_workplace_2020',\n",
    "    'hotels_2024_sum',\n",
    "    'camping_sites_2024_sum',\n",
    "    'other_tourist_accommodations_2024_sum'\n",
    "]\n",
    "\n",
    "# Box plots for numerical variables\n",
    "for col in numerical_columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    dataRead.boxplot(column=[col])\n",
    "    plt.title(f'Box plot for {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes= plt.subplots(1,2, gridspec_kw={'width_ratios': [1, 4]}, figsize=(9,5))\n",
    "dataRead.boxplot(column='total_passengers_2022',ax=axes[0]);\n",
    "dataRead.hist(column='total_passengers_2022', ax=axes[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = dataRead['total_passengers_2022'].quantile(0.25)\n",
    "Q3 = dataRead['total_passengers_2022'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "Q1, Q3, IQR\n",
    "\n",
    "small_outliers = dataRead['total_passengers_2022'] < (Q1 - 1.5 * IQR)\n",
    "big_outliers = dataRead['total_passengers_2022'] > (Q3 + 1.5 * IQR)\n",
    "\n",
    "sum(small_outliers), sum(big_outliers)\n",
    "\n",
    "dataRead['total_passengers_2022'][small_outliers | big_outliers].head()\n",
    "fig, axes= plt.subplots(1,2, gridspec_kw={'width_ratios': [1, 4]}, figsize=(9,5))\n",
    "dataRead[~(small_outliers | big_outliers)].boxplot(column='total_passengers_2022',ax=axes[0]);\n",
    "dataRead[~(small_outliers | big_outliers)].hist(column='total_passengers_2022', ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## SECTION 5: TREATMENT OF MIXED DATA TYPES\n",
    "\n",
    "\n",
    " In this case we have decided to keep the original type and leave the decision for later, depending on the specific analysis\n",
    "\n",
    " we explicitly declare categorical variables as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 6: DERIVATION OF NEW VARIABLES: FEATURE EXTRACTION\n",
    "\n",
    " We decide whether it can be sensible to derive new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Passenger Growth Rate\n",
    "dataRead['passenger_growth_rate'] = (dataRead['total_passengers_2022'] - dataRead['total_passengers_2015']) / dataRead['total_passengers_2015']\n",
    "dataRead['passenger_growth_rate'].hist(figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Attraction Density\n",
    "dataRead['attraction_density'] = (dataRead['hotels_2024_sum'] + dataRead['camping_sites_2024_sum'] + dataRead['other_tourist_accommodations_2024_sum']) / dataRead['sum_municipal_population_2021']\n",
    "dataRead['attraction_density'].hist(bins=16, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. City Size Category\n",
    "def categorize_city_size(population):\n",
    "    if population < 50000:\n",
    "        return 'Small'\n",
    "    elif 50000 <= population < 200000:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Large'\n",
    "\n",
    "dataRead['city_size_category'] = dataRead['sum_municipal_population_2021'].apply(categorize_city_size)\n",
    "\n",
    "# Mark dubious cities based on passenger growth rate and municipal population\n",
    "dataRead['Dubious'] = ['No'] * dataRead.shape[0]\n",
    "dataRead.loc[\n",
    "    (dataRead['passenger_growth_rate'] > dataRead['passenger_growth_rate'].median(skipna=True)) &\n",
    "    (dataRead['sum_municipal_population_2021'] < 1.25 * dataRead['sum_municipal_population_2021'].mean(skipna=True)), \n",
    "    'Dubious'\n",
    "] = \"Yes\"\n",
    "\n",
    "# Crosstab of Dubious and city_size_category\n",
    "dubious_crosstab = pd.crosstab(dataRead['Dubious'], dataRead['city_size_category'])\n",
    "dubious_crosstab\n",
    "dataRead[['passenger_growth_rate', 'attraction_density', 'city_size_category', 'Dubious']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Non passengers only\n",
    "dataRead['total_non_passengers_2022'] = dataRead['total_passengers_and_non_passengers_2022'] - dataRead['total_passengers_2022']\n",
    "dataRead['total_non_passengers_2015'] = dataRead['total_passengers_and_non_passengers_2015'] - dataRead['total_passengers_2015']\n",
    "\n",
    "# 5. Non passenger growth rate\n",
    "dataRead['non_passenger_growth_rate'] = np.where(\n",
    "    dataRead['total_non_passengers_2015'] == 0,\n",
    "    0,\n",
    "    (dataRead['total_non_passengers_2022'] - dataRead['total_non_passengers_2015']) / dataRead['total_non_passengers_2015']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Distance to Paris\n",
    "# Convert latitude and longitude to float\n",
    "dataRead['latitude'] = dataRead['latitude'].astype(float)\n",
    "dataRead['longitude'] = dataRead['longitude'].astype(float)\n",
    "\n",
    "dataRead['distance_to_paris'] = dataRead.apply(lambda row: distance_to_paris(row['latitude'], row['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## SECTION 7: WHAT WE HAVE DONE SO FAR\n",
    "\n",
    "\n",
    " Create a new dataframe that gathers everything and inspect it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead_new =dataRead.copy()\n",
    "\n",
    "dataRead_new.describe(include='all')\n",
    "dataRead_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## SECTION 8: GAUSSIANITY AND TRANSFORMATIONS\n",
    "\n",
    "\n",
    "Performing a graphical summary of some of the variables helps understand their distributions, identify outliers, and assess the need for transformations to approximate a Gaussian (normal) distribution. This section covers histograms and boxplots for continuous variables, as well as bar charts for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continuous numerical columns\n",
    "continuous_columns = [\n",
    "    'total_passengers_2022',\n",
    "    'total_passengers_and_non_passengers_2022',\n",
    "    'total_passengers_2015',\n",
    "    'total_passengers_and_non_passengers_2015',\n",
    "    'total_non_passengers_2022',\n",
    "    'total_non_passengers_2015',\n",
    "    'passenger_growth_rate',\n",
    "    'non_passenger_growth_rate',\n",
    "    'attraction_density'\n",
    "]\n",
    "\n",
    "# Plot histograms for continuous variables\n",
    "for col in continuous_columns:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.hist(dataRead_new[col].dropna(), bins=30, edgecolor='k', alpha=0.7, color='green')\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for continuous variables\n",
    "for col in continuous_columns:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    dataRead_new.boxplot(column=[col])\n",
    "    plt.title(f'Box plot of {col}')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "# Apply log transformation and plot histograms\n",
    "log_transformed_columns = ['total_passengers_2022',\n",
    "                           'total_passengers_and_non_passengers_2022',\n",
    "                           'total_non_passengers_2022',\n",
    "                           'total_passengers_2015',\n",
    "                           'total_passengers_and_non_passengers_2015',\n",
    "                           'total_non_passengers_2015']\n",
    "\n",
    "for col in log_transformed_columns:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    dataRead_new[col].apply(np.log1p).hist(bins=30, edgecolor='k', alpha=0.7, color='red')\n",
    "    plt.title(f'Log-Transformed Histogram of {col}')\n",
    "    plt.xlabel(f'log1p({col})')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns\n",
    "categorical_columns = [\n",
    "    'drg_segment',\n",
    "    'city_label',\n",
    "    'city_attraction_area',\n",
    "    'city_size_category',\n",
    "    'Dubious'\n",
    "]\n",
    "\n",
    "# Plot bar charts for categorical variables\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    dataRead_new[col].value_counts().plot(kind='bar', edgecolor='k', alpha=0.7, color='blue')\n",
    "    plt.title(f'Bar chart of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins for population categories\n",
    "population_bins = pd.interval_range(start=0, end=dataRead_new['sum_municipal_population_2021'].max()+1, freq=300000)\n",
    "dataRead_new['population_category'] = pd.cut(dataRead_new['sum_municipal_population_2021'], bins=population_bins)\n",
    "\n",
    "# Plot bar chart for the new categorical variable\n",
    "dataRead_new['population_category'].value_counts().sort_index().plot.bar(figsize=(8, 8))\n",
    "plt.title('Bar chart of population categories')\n",
    "plt.xlabel('Population Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Creating another categorical variable based on a threshold\n",
    "dataRead_new['high_population'] = dataRead_new['sum_municipal_population_2021'].apply(lambda x: 'High' if x >= 300000 else 'Low')\n",
    "\n",
    "# Crosstabulation and bar chart\n",
    "population_crosstab = pd.crosstab(dataRead_new['high_population'], dataRead_new['city_size_category'])\n",
    "population_crosstab.plot.bar(stacked=True, figsize=(8, 8), color=['green', 'red', 'blue'])\n",
    "plt.title('Population Category by City Size')\n",
    "plt.xlabel('High Population')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoder\n",
    "Transform categorical variables into binary vectors using one-hot encoding.\n",
    "This is necessary for machine learning models that require numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRead_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "columns_to_encode = ['drg_segment',\n",
    "                     'wifi_service',\n",
    "                     'city_attraction_area',\n",
    "                     'city_size_category',\n",
    "                     'Dubious',\n",
    "                     'high_population',\n",
    "                     ]\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_data = ohe.fit_transform(dataRead_new[columns_to_encode])\n",
    " \n",
    "# Create a DataFrame from the encoded data\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=ohe.get_feature_names_out(columns_to_encode))\n",
    "\n",
    "result_df = pd.concat([dataRead_new.drop(columns_to_encode, axis=1), encoded_df], axis=1)\n",
    "\n",
    "result_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION:9 NORMALIZATION\n",
    "\n",
    "If you try to train a model with varaibles of ranges too far away it will be a disaster most of the times. Becasue the model might only \"see\" the bigger variable.\n",
    "\n",
    "To avoid this issue you usualy normalize or standarize your data. This way you force all your variables to have the same range.\n",
    "There are models that are very sensitive to this and might even fail to converge if you don't normalize your data.\n",
    "\n",
    "The most comon transformations for normalizing the data are:\n",
    "* Standarization: $\\frac{X - \\mu}{\\sigma}$ will trasnform your data so it has mean 0 and std 1.\n",
    "* Min-max scaling: $\\frac{X - X_{min}}{X_{max} - X_{min}}$ will send your data to the range [0,1]\n",
    "* Boxcox transformation: $\\frac{X^\\lambda - 1}{ \\lambda}$ if $\\lambda \\neq 0$ or $ln(X)$ if $\\lambda = 0$ transforms the data to try to fit a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert infinite values to NaN\n",
    "dataRead_new.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Summary statistics before normalization\n",
    "dataRead_new[['total_passengers_2022', 'total_passengers_and_non_passengers_2022']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scaling\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dataRead_new[['total_passengers_2022_min_max', 'total_passengers_and_non_passengers_2022_min_max']] = min_max_scaler.fit_transform(dataRead_new[['total_passengers_2022', 'total_passengers_and_non_passengers_2022']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "dataRead_new[['total_passengers_2022_std', 'total_passengers_and_non_passengers_2022_std']] = std_scaler.fit_transform(dataRead_new[['total_passengers_2022', 'total_passengers_and_non_passengers_2022']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxcox transformation\n",
    "# Adding a small constant to avoid log of zero\n",
    "dataRead_new['total_passengers_2022_bx'], _ = boxcox(dataRead_new['total_passengers_2022'] + 1)\n",
    "dataRead_new['total_passengers_and_non_passengers_2022_bx'], _ = boxcox(dataRead_new['total_passengers_and_non_passengers_2022'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics after normalization\n",
    "dataRead_new[['total_passengers_2022_min_max', 'total_passengers_and_non_passengers_2022_min_max',\n",
    "              'total_passengers_2022_std', 'total_passengers_and_non_passengers_2022_std',\n",
    "              'total_passengers_2022_bx', 'total_passengers_and_non_passengers_2022_bx']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for the original and transformed variables\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Original histograms\n",
    "dataRead_new['total_passengers_2022'].hist(bins=30, ax=axes[0, 0], color='green')\n",
    "axes[0, 0].set_title('Original total_passengers_2022')\n",
    "dataRead_new['total_passengers_and_non_passengers_2022'].hist(bins=30, ax=axes[0, 1], color='green')\n",
    "axes[0, 1].set_title('Original total_passengers_and_non_passengers_2022')\n",
    "\n",
    "# Min-max scaled histograms\n",
    "dataRead_new['total_passengers_2022_min_max'].hist(bins=30, ax=axes[0, 2], color='red')\n",
    "axes[0, 2].set_title('Min-max scaled total_passengers_2022')\n",
    "dataRead_new['total_passengers_and_non_passengers_2022_min_max'].hist(bins=30, ax=axes[0, 3], color='red')\n",
    "axes[0, 3].set_title('Min-max scaled total_passengers_and_non_passengers_2022')\n",
    "\n",
    "# Standardized histograms\n",
    "dataRead_new['total_passengers_2022_std'].hist(bins=30, ax=axes[1, 0], color='blue')\n",
    "axes[1, 0].set_title('Standardized total_passengers_2022')\n",
    "dataRead_new['total_passengers_and_non_passengers_2022_std'].hist(bins=30, ax=axes[1, 1], color='blue')\n",
    "axes[1, 1].set_title('Standardized total_passengers_and_non_passengers_2022')\n",
    "\n",
    "# Boxcox transformed histograms\n",
    "dataRead_new['total_passengers_2022_bx'].hist(bins=30, ax=axes[1, 2], color='purple')\n",
    "axes[1, 2].set_title('Boxcox transformed total_passengers_2022')\n",
    "dataRead_new['total_passengers_and_non_passengers_2022_bx'].hist(bins=30, ax=axes[1, 3], color='purple')\n",
    "axes[1, 3].set_title('Boxcox transformed total_passengers_and_non_passengers_2022')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra plot for Boxcox transformation\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "dataRead_new['total_passengers_2022'].plot.hist(title='Original total_passengers_2022', ax=ax)\n",
    "\n",
    "# Apply Boxcox transformation\n",
    "x, _ = boxcox(dataRead_new['total_passengers_2022'] + 1)\n",
    "dataRead_new['total_passengers_2022_BC'] = x\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "dataRead_new['total_passengers_2022_BC'].plot.hist(title='Boxcox transformed total_passengers_2022', ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 10: FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataRead_new.copy()\n",
    "dataset.columns\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=[\n",
    "    'city_name',\n",
    "    'total_passengers_and_non_passengers_2022',\n",
    "    'total_passengers_2015',\n",
    "    'total_passengers_and_non_passengers_2015',\n",
    "    'city_label',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 10: ENDING THE PREPROCESSING\n",
    "\n",
    "  \n",
    " Shuffle the data (to avoid possible ordering biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "np.random.seed(144)\n",
    "\n",
    "# Shuffle the data\n",
    "dataRead_new = dataRead_new.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data as a pickle file with compression\n",
    "dataRead_new.to_pickle('dataRead_processed.pkl.bz2', compression='bz2')\n",
    "dataRead_new.to_csv('dataset_preprocessed.csv', index=False)\n",
    "\n",
    "# Load the preprocessed data to verify\n",
    "dataRead_load = pd.read_pickle('dataRead_processed.pkl.bz2', compression='bz2')\n",
    "\n",
    "# Display the first few rows of the loaded data\n",
    "dataRead_load.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
