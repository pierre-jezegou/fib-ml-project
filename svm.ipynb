{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy.stats import chi2_contingency \n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error, mean_absolute_error\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from sklearn.svm import LinearSVR, SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from dython.nominal import associations\n",
    "from dython.nominal import correlation_ratio\n",
    "from dython.nominal import cramers_v\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from get_metrics import write_metrics_in_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN TWICE THE PREVIOUS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset\n",
    "filename: str = 'dataset.csv'\n",
    "dataset = pd.read_pickle('dataRead_processed.pkl.bz2', compression='bz2')\n",
    "\n",
    "# Split dataset\n",
    "X = dataset.drop(columns=['total_passengers_2022'])\n",
    "y = dataset['total_passengers_2022']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['total_passengers_and_non_passengers_2022', 'total_passengers_and_non_passengers_2015', 'total_passengers_2015'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_preprocessing(X, y):\n",
    "    print('Original shape:{}'.format(X.shape))\n",
    "    # We kill categorical columns\n",
    "    X = X.drop(columns=X.select_dtypes(include='object').columns)\n",
    "    X = X.drop(columns=X.select_dtypes(include='category').columns)\n",
    "    # We remove missing values\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    # Normalize\n",
    "    \n",
    "    print(X.dtypes)\n",
    "    # X = minmax_scale(X)\n",
    "    # print('New shape:{}'.format(X.shape))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = minimum_preprocessing(X_train,y_train)\n",
    "X_test, y_test = minimum_preprocessing(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVR()\n",
    "\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "model = 'SVR'\n",
    "hyperparameters = {'type': 'linear', 'C': 1, 'epsilon': 0}\n",
    "\n",
    "write_metrics_in_csv(y_test, y_pred, model, hyperparameters)\n",
    "\n",
    "# sns.scatterplot(x=y_test, y=y_pred)\n",
    "sns.scatterplot(x=np.log(y_test), y=np.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.1, 1, 10, 100, 1000]\n",
    "epsilons = [0, 0.1, 0.01, 0.001]\n",
    "\n",
    "model = 'SVR'\n",
    "kernel = 'linear'\n",
    "\n",
    "for c in Cs:\n",
    "    print(f'c: {c}')\n",
    "    for epsilon in epsilons:\n",
    "        print(f'\\tepsilon: {epsilon}')\n",
    "        svm = LinearSVR(C=c, epsilon=epsilon)\n",
    "        svm.fit(X_train,y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        hyperparameters = {\n",
    "            'type': kernel,\n",
    "            'C': c,\n",
    "            'epsilon': epsilon\n",
    "        }\n",
    "        write_metrics_in_csv(y_test, y_pred, model, hyperparameters)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "    'degree': [2, 3, 4],  # For the polynomial kernel\n",
    "    'epsilon': [0.01, 0.1, 0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "# Train the SVR model with the best hyperparameters\n",
    "best_svr = grid_search.best_estimator_\n",
    "best_svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_svr.predict(X_test)\n",
    "\n",
    "# Inverse the normalization of the predictions\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred.reshape(1, -1))\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(1, -1))\n",
    "\n",
    "y_pred_reshaped = y_pred_inv.reshape(-1)\n",
    "y_test_reshaped = y_test_inv.reshape(-1)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(y_test_inv, y_pred_inv, color='orange', label='Data', alpha=0.5)\n",
    "plt.plot([min(y_test_reshaped), max(y_test_reshaped)], [min(y_test_reshaped), max(y_test_reshaped)], '--', color='navy', label='Perfect')\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title('Support Vector Regression with Hyperparameter Optimization')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "svm = SVR(kernel=best_parameters['kernel'],\n",
    "          C=best_parameters['C'],\n",
    "          gamma=best_parameters['gamma'],\n",
    "          degree=best_parameters['degree'],\n",
    "          epsilon=best_parameters['epsilon'])\n",
    "\n",
    "sns.scatterplot(x=y_test_inv.reshape(-1), y=y_pred_inv.reshape(-1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
