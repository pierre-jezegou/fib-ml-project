{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "Use K nearest neighbors for our regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error, mean_absolute_error\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from get_metrics import write_metrics_in_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataset\n",
    "filename: str = 'dataset.csv'\n",
    "dataset = pd.read_pickle('dataRead_processed.pkl.bz2', compression='bz2')\n",
    "\n",
    "# Split dataset\n",
    "X = dataset.drop(columns=['total_passengers_2022'])\n",
    "y = dataset['total_passengers_2022']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common functions (metrics for instance)\n",
    "def comptue_metrics(y_pred, y_real):\n",
    "    r2 = r2_score(y_pred,y_real)\n",
    "    mse = mean_squared_error(y_pred, y_real)\n",
    "    median_abs_e = median_absolute_error(y_pred, y_real)\n",
    "    mean_abs_e = mean_absolute_error(y_pred, y_real)\n",
    "    return [r2, mse, median_abs_e, mean_abs_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also instantiate our results dataframe\n",
    "results = pd.DataFrame(columns=['Kernel', 'C', 'epsilon', 'R2', 'MSE', 'median_absolute_error', 'mean_absolute_error'])\n",
    "\n",
    "def minimum_preprocessing(X, y):\n",
    "    print('Original shape:{}'.format(X.shape))\n",
    "    # Remove non numeric columns\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    # We remove missing values\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    # Normalize\n",
    "    X = minmax_scale(X)\n",
    "    print('New shape:{}'.format(X.shape))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = minimum_preprocessing(X_train,y_train)\n",
    "X_test, y_test = minimum_preprocessing(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple KNN model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "results.loc['KNN', :] = ['-', '-', '-'] + comptue_metrics(y_pred,y_test)\n",
    "\n",
    "sns.scatterplot(x=np.log(y_test), y=np.log(y_pred))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning: k of k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex model\n",
    "train_score = {}\n",
    "test_score = {}\n",
    "n_neighbors = np.arange(1, 30, 1)\n",
    "\n",
    "for neighbor in n_neighbors:\n",
    "    knn = KNeighborsRegressor(n_neighbors=neighbor)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score[neighbor]=knn.score(X_train, y_train)\n",
    "    test_score[neighbor]=knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_neighbors, train_score.values(), label=\"Train Accuracy\")\n",
    "plt.plot(n_neighbors, test_score.values(), label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Number Of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"KNN: Varying number of Neighbors\")\n",
    "plt.legend()\n",
    "plt.xlim(0, 33)\n",
    "plt.ylim(0.60, 1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Parameter tuning\n",
    "kf=KFold(n_splits=20,shuffle=True,random_state=42)\n",
    "parameter={'n_neighbors': np.arange(2, 30, 1)}\n",
    "knn=KNeighborsRegressor()\n",
    "knn_cv=GridSearchCV(knn, param_grid=parameter, cv=kf, verbose=1)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "print(knn_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_k = knn_cv.best_params_['n_neighbors']\n",
    "# Use the best hyperparameter and train the final model\n",
    "knn = KNeighborsRegressor(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "sns.scatterplot(x=np.log(y_test), y=np.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "model = 'KNN'\n",
    "hyperparameters = {'k': best_k}\n",
    "write_metrics_in_csv(y_pred, y_test, model, hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
